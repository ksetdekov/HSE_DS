{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in ./venv/lib/python3.6/site-packages (3.1.2)\n",
      "Requirement already satisfied: findspark in ./venv/lib/python3.6/site-packages (1.4.2)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: py4j==0.10.9 in ./venv/lib/python3.6/site-packages (from pyspark) (0.10.9)\n",
      "Collecting numpy>=1.15.4\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 28.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in ./venv/lib/python3.6/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 86.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in ./venv/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "Successfully installed numpy-1.19.5 pandas-1.1.5 pytz-2021.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark findspark pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6285cef5-5ea3-43d0-ae5b-0fef3cbaa521",
     "showTitle": true,
     "title": "Group by "
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|Raman        |Finance   |CA   |99000 |40 |24000|\n",
      "|Scott        |Finance   |NY   |83000 |36 |19000|\n",
      "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000),\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,40,24000),\n",
    "    (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000),\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000)\n",
    "  ]\n",
    "\n",
    "schema = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "822473f4-6b62-4e94-9a6a-6d55ac062871",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|department|sum(salary)|\n",
      "+----------+-----------+\n",
      "|Sales     |257000     |\n",
      "|Finance   |351000     |\n",
      "|Marketing |171000     |\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"department\").sum(\"salary\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cbc8b67c-e5ca-4925-96a5-c5524699d379",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|department|count|\n",
      "+----------+-----+\n",
      "|Sales     |3    |\n",
      "|Finance   |4    |\n",
      "|Marketing |2    |\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"department\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1dd8bb9a-3737-480f-8ec8-d02971aacb75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------+----------+\n",
      "|department|state|sum(salary)|sum(bonus)|\n",
      "+----------+-----+-----------+----------+\n",
      "|Finance   |NY   |162000     |34000     |\n",
      "|Marketing |NY   |91000      |21000     |\n",
      "|Sales     |CA   |81000      |23000     |\n",
      "|Marketing |CA   |80000      |18000     |\n",
      "|Finance   |CA   |189000     |47000     |\n",
      "|Sales     |NY   |176000     |30000     |\n",
      "+----------+-----+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"department\",\"state\") \\\n",
    "    .sum(\"salary\",\"bonus\") \\\n",
    "   .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "acedf521-86f9-4d8b-8ede-320ad43c0308",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+---------+---------+\n",
      "|department|sum_salary|avg_salary       |sum_bonus|max_bonus|\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "|Sales     |257000    |85666.66666666667|53000    |23000    |\n",
      "|Finance   |351000    |87750.0          |81000    |24000    |\n",
      "|Marketing |171000    |85500.0          |39000    |21000    |\n",
      "+----------+----------+-----------------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.groupBy(\"department\") \\\n",
    "    .agg(\n",
    "  F.sum(\"salary\").alias(\"sum_salary\"), \\\n",
    "         F.avg(\"salary\").alias(\"avg_salary\"), \\\n",
    "         F.sum(\"bonus\").alias(\"sum_bonus\"), \\\n",
    "         F.max(\"bonus\").alias(\"max_bonus\") \\\n",
    "     ) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d5b0fe66-8b82-4d9c-b555-5898fa5023b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>sum_salary</th>\n",
       "      <th>avg_salary</th>\n",
       "      <th>sum_bonus</th>\n",
       "      <th>max_bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sales</td>\n",
       "      <td>257000</td>\n",
       "      <td>85666.666667</td>\n",
       "      <td>53000</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finance</td>\n",
       "      <td>351000</td>\n",
       "      <td>87750.000000</td>\n",
       "      <td>81000</td>\n",
       "      <td>24000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marketing</td>\n",
       "      <td>171000</td>\n",
       "      <td>85500.000000</td>\n",
       "      <td>39000</td>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  department  sum_salary    avg_salary  sum_bonus  max_bonus\n",
       "0      Sales      257000  85666.666667      53000      23000\n",
       "1    Finance      351000  87750.000000      81000      24000\n",
       "2  Marketing      171000  85500.000000      39000      21000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"department\") \\\n",
    "    .agg(\n",
    "  F.sum(\"salary\").alias(\"sum_salary\"), \\\n",
    "         F.avg(\"salary\").alias(\"avg_salary\"), \\\n",
    "         F.sum(\"bonus\").alias(\"sum_bonus\"), \\\n",
    "         F.max(\"bonus\").alias(\"max_bonus\") \\\n",
    "     ) \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode('overwrite').parquet('./test_df.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0K\t./test_df.parquet/part-00000-79157ecc-18c1-4c4c-8d2a-2015effe1646-c000.snappy.parquet\r\n",
      "4.0K\t./test_df.parquet/part-00001-79157ecc-18c1-4c4c-8d2a-2015effe1646-c000.snappy.parquet\r\n",
      "0\t./test_df.parquet/_SUCCESS\r\n"
     ]
    }
   ],
   "source": [
    "!du -h -d 2 ./test_df.parquet/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-02 15:45:24--  https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 203415 (199K) [application/x-httpd-php]\n",
      "Saving to: ‘smsspamcollection.zip’\n",
      "\n",
      "smsspamcollection.z 100%[===================>] 198.65K   262KB/s    in 0.8s    \n",
      "\n",
      "2021-10-02 15:45:25 (262 KB/s) - ‘smsspamcollection.zip’ saved [203415/203415]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Seminar3.ipynb\t\t\t   spark_environ.sh\r\n",
      " smsspamcollection.zip\t\t   test_df.parquet\r\n",
      " spark-3.1.2-bin-hadoop2.7.tgz\t  'test notebook.ipynb'\r\n",
      " spark-3.1.2-bin-hadoop2.7.tgz.1   venv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  smsspamcollection.zip\n",
      "  inflating: SMSSpamCollection       \n",
      "  inflating: readme                  \n"
     ]
    }
   ],
   "source": [
    "!unzip smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = (\n",
    "    spark\n",
    "    .read\n",
    "    .option(\"sep\", \"\\t\")\n",
    "    .csv(\"./SMSSpamCollection\")\n",
    "    .withColumnRenamed(\"_c0\", \"label\")\n",
    "    .withColumnRenamed(\"_c1\", \"message\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.write.partitionBy('label').mode('overwrite').parquet('./test_df.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256K\t./test_df.parquet/label=ham\r\n",
      "68K\t./test_df.parquet/label=spam\r\n",
      "0\t./test_df.parquet/_SUCCESS\r\n"
     ]
    }
   ],
   "source": [
    "!du -h -d 2 ./test_df.parquet/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message\n",
       "0  Go until jurong point, crazy.. Available only ...\n",
       "1                      Ok lar... Joking wif u oni...\n",
       "2  U dun say so early hor... U c already then say...\n",
       "3  Nah I don't think he goes to usf, he lives aro...\n",
       "4  Even my brother is not like to speak with me. ...\n",
       "5  As per your request 'Melle Melle (Oru Minnamin...\n",
       "6  I'm gonna be home soon and i don't want to tal...\n",
       "7  I've been searching for the right words to tha...\n",
       "8                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "9                         Oh k...i'm watching here:)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham = spark.read.parquet('./test_df.parquet/label=ham')\n",
    "ham.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332K\t./test_df.parquet/label=ham\r\n",
      "152K\t./test_df.parquet/label=spam\r\n",
      "0\t./test_df.parquet/_SUCCESS\r\n"
     ]
    }
   ],
   "source": [
    "src.repartition(10).write.partitionBy('label').mode('overwrite').parquet('./test_df.parquet')  # это не очень хорошее действи\n",
    "# делать партишт бай перед записью большими данными\n",
    "# а репартшишн - на более мелкое число партиций\n",
    "!du -h -d 2 ./test_df.parquet/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.join().join().groupby().repartition() # - это хорошая вещь посл групбай"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "87aec793-2c9b-402f-bfc8-26b2f23afa6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-70984e868960>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"department\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n\u001b[0m\u001b[1;32m      3\u001b[0m       \u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"salary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"avg_salary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bonus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sum_bonus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       max(\"bonus\").alias(\"max_bonus\")) \\\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"department\") \\\n",
    "    .agg(sum(\"salary\").alias(\"sum_salary\"), \\\n",
    "      avg(\"salary\").alias(\"avg_salary\"), \\\n",
    "      sum(\"bonus\").alias(\"sum_bonus\"), \\\n",
    "      max(\"bonus\").alias(\"max_bonus\")) \\\n",
    "    .where(col(\"sum_bonus\") >= 50000) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "64e4d6b0-9de4-4356-ac27-e8b5178ed7be",
     "showTitle": true,
     "title": "Window functions"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">root\n",
       "-- employee_name: string (nullable = true)\n",
       "-- department: string (nullable = true)\n",
       "-- salary: long (nullable = true)\n",
       "\n",
       "+-------------+----------+------+\n",
       "employee_name|department|salary|\n",
       "+-------------+----------+------+\n",
       "James        |Sales     |3000  |\n",
       "Michael      |Sales     |4600  |\n",
       "Robert       |Sales     |4100  |\n",
       "Maria        |Finance   |3000  |\n",
       "James        |Sales     |3000  |\n",
       "Scott        |Finance   |3300  |\n",
       "Jen          |Finance   |3900  |\n",
       "Jeff         |Marketing |3000  |\n",
       "Kumar        |Marketing |2000  |\n",
       "Saif         |Sales     |4100  |\n",
       "+-------------+----------+------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+-------------+----------+------+\n|employee_name|department|salary|\n+-------------+----------+------+\n|James        |Sales     |3000  |\n|Michael      |Sales     |4600  |\n|Robert       |Sales     |4100  |\n|Maria        |Finance   |3000  |\n|James        |Sales     |3000  |\n|Scott        |Finance   |3300  |\n|Jen          |Finance   |3900  |\n|Jeff         |Marketing |3000  |\n|Kumar        |Marketing |2000  |\n|Saif         |Sales     |4100  |\n+-------------+----------+------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "simpleData = ((\"James\", \"Sales\", 3000), \\\n",
    "    (\"Michael\", \"Sales\", 4600),  \\\n",
    "    (\"Robert\", \"Sales\", 4100),   \\\n",
    "    (\"Maria\", \"Finance\", 3000),  \\\n",
    "    (\"James\", \"Sales\", 3000),    \\\n",
    "    (\"Scott\", \"Finance\", 3300),  \\\n",
    "    (\"Jen\", \"Finance\", 3900),    \\\n",
    "    (\"Jeff\", \"Marketing\", 3000), \\\n",
    "    (\"Kumar\", \"Marketing\", 2000),\\\n",
    "    (\"Saif\", \"Sales\", 4100) \\\n",
    "  )\n",
    " \n",
    "columns= [\"employee_name\", \"department\", \"salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c8fea13b-e5e3-4bdb-9eca-cb50c6ad207f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------------+----------+------+----------+\n",
       "employee_name|department|salary|row_number|\n",
       "+-------------+----------+------+----------+\n",
       "Maria        |Finance   |3000  |1         |\n",
       "Scott        |Finance   |3300  |2         |\n",
       "Jen          |Finance   |3900  |3         |\n",
       "Kumar        |Marketing |2000  |1         |\n",
       "Jeff         |Marketing |3000  |2         |\n",
       "James        |Sales     |3000  |1         |\n",
       "James        |Sales     |3000  |2         |\n",
       "Robert       |Sales     |4100  |3         |\n",
       "Saif         |Sales     |4100  |4         |\n",
       "Michael      |Sales     |4600  |5         |\n",
       "+-------------+----------+------+----------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-------------+----------+------+----------+\n|employee_name|department|salary|row_number|\n+-------------+----------+------+----------+\n|Maria        |Finance   |3000  |1         |\n|Scott        |Finance   |3300  |2         |\n|Jen          |Finance   |3900  |3         |\n|Kumar        |Marketing |2000  |1         |\n|Jeff         |Marketing |3000  |2         |\n|James        |Sales     |3000  |1         |\n|James        |Sales     |3000  |2         |\n|Robert       |Sales     |4100  |3         |\n|Saif         |Sales     |4100  |4         |\n|Michael      |Sales     |4600  |5         |\n+-------------+----------+------+----------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "windowSpec  = Window.partitionBy(\"department\").orderBy(\"salary\")\n",
    "\n",
    "df.withColumn(\"row_number\",row_number().over(windowSpec)) \\\n",
    "    .show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a23fdcd4-75a7-40da-997f-af8e933ad84c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------------+----------+------+----+\n",
       "employee_name|department|salary|rank|\n",
       "+-------------+----------+------+----+\n",
       "        Maria|   Finance|  3000|   1|\n",
       "        Scott|   Finance|  3300|   2|\n",
       "          Jen|   Finance|  3900|   3|\n",
       "        Kumar| Marketing|  2000|   1|\n",
       "         Jeff| Marketing|  3000|   2|\n",
       "        James|     Sales|  3000|   1|\n",
       "        James|     Sales|  3000|   1|\n",
       "       Robert|     Sales|  4100|   3|\n",
       "         Saif|     Sales|  4100|   3|\n",
       "      Michael|     Sales|  4600|   5|\n",
       "+-------------+----------+------+----+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-------------+----------+------+----+\n|employee_name|department|salary|rank|\n+-------------+----------+------+----+\n|        Maria|   Finance|  3000|   1|\n|        Scott|   Finance|  3300|   2|\n|          Jen|   Finance|  3900|   3|\n|        Kumar| Marketing|  2000|   1|\n|         Jeff| Marketing|  3000|   2|\n|        James|     Sales|  3000|   1|\n|        James|     Sales|  3000|   1|\n|       Robert|     Sales|  4100|   3|\n|         Saif|     Sales|  4100|   3|\n|      Michael|     Sales|  4600|   5|\n+-------------+----------+------+----+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import rank\n",
    "df.withColumn(\"rank\",rank().over(windowSpec)) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b705ede4-39f5-49c4-a75f-e37ceb398511",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------------+----------+------+----------+\n",
       "employee_name|department|salary|dense_rank|\n",
       "+-------------+----------+------+----------+\n",
       "        Maria|   Finance|  3000|         1|\n",
       "        Scott|   Finance|  3300|         2|\n",
       "          Jen|   Finance|  3900|         3|\n",
       "        Kumar| Marketing|  2000|         1|\n",
       "         Jeff| Marketing|  3000|         2|\n",
       "        James|     Sales|  3000|         1|\n",
       "        James|     Sales|  3000|         1|\n",
       "       Robert|     Sales|  4100|         2|\n",
       "         Saif|     Sales|  4100|         2|\n",
       "      Michael|     Sales|  4600|         3|\n",
       "+-------------+----------+------+----------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-------------+----------+------+----------+\n|employee_name|department|salary|dense_rank|\n+-------------+----------+------+----------+\n|        Maria|   Finance|  3000|         1|\n|        Scott|   Finance|  3300|         2|\n|          Jen|   Finance|  3900|         3|\n|        Kumar| Marketing|  2000|         1|\n|         Jeff| Marketing|  3000|         2|\n|        James|     Sales|  3000|         1|\n|        James|     Sales|  3000|         1|\n|       Robert|     Sales|  4100|         2|\n|         Saif|     Sales|  4100|         2|\n|      Michael|     Sales|  4600|         3|\n+-------------+----------+------+----------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import dense_rank\n",
    "df.withColumn(\"dense_rank\",dense_rank().over(windowSpec)) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "aac41e6b-e695-412b-8940-ba027f8d9e25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------------+----------+------+------------+\n",
       "employee_name|department|salary|percent_rank|\n",
       "+-------------+----------+------+------------+\n",
       "        Maria|   Finance|  3000|         0.0|\n",
       "        Scott|   Finance|  3300|         0.5|\n",
       "          Jen|   Finance|  3900|         1.0|\n",
       "        Kumar| Marketing|  2000|         0.0|\n",
       "         Jeff| Marketing|  3000|         1.0|\n",
       "        James|     Sales|  3000|         0.0|\n",
       "        James|     Sales|  3000|         0.0|\n",
       "       Robert|     Sales|  4100|         0.5|\n",
       "         Saif|     Sales|  4100|         0.5|\n",
       "      Michael|     Sales|  4600|         1.0|\n",
       "+-------------+----------+------+------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-------------+----------+------+------------+\n|employee_name|department|salary|percent_rank|\n+-------------+----------+------+------------+\n|        Maria|   Finance|  3000|         0.0|\n|        Scott|   Finance|  3300|         0.5|\n|          Jen|   Finance|  3900|         1.0|\n|        Kumar| Marketing|  2000|         0.0|\n|         Jeff| Marketing|  3000|         1.0|\n|        James|     Sales|  3000|         0.0|\n|        James|     Sales|  3000|         0.0|\n|       Robert|     Sales|  4100|         0.5|\n|         Saif|     Sales|  4100|         0.5|\n|      Michael|     Sales|  4600|         1.0|\n+-------------+----------+------+------------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import percent_rank\n",
    "df.withColumn(\"percent_rank\",percent_rank().over(windowSpec)) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "206aff7b-94d2-4c6e-9eaf-f49e6ae17482",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------------+----------+------+-----+\n",
       "employee_name|department|salary|ntile|\n",
       "+-------------+----------+------+-----+\n",
       "        Maria|   Finance|  3000|    1|\n",
       "        Scott|   Finance|  3300|    1|\n",
       "          Jen|   Finance|  3900|    2|\n",
       "        Kumar| Marketing|  2000|    1|\n",
       "         Jeff| Marketing|  3000|    2|\n",
       "        James|     Sales|  3000|    1|\n",
       "        James|     Sales|  3000|    1|\n",
       "       Robert|     Sales|  4100|    1|\n",
       "         Saif|     Sales|  4100|    2|\n",
       "      Michael|     Sales|  4600|    2|\n",
       "+-------------+----------+------+-----+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-------------+----------+------+-----+\n|employee_name|department|salary|ntile|\n+-------------+----------+------+-----+\n|        Maria|   Finance|  3000|    1|\n|        Scott|   Finance|  3300|    1|\n|          Jen|   Finance|  3900|    2|\n|        Kumar| Marketing|  2000|    1|\n|         Jeff| Marketing|  3000|    2|\n|        James|     Sales|  3000|    1|\n|        James|     Sales|  3000|    1|\n|       Robert|     Sales|  4100|    1|\n|         Saif|     Sales|  4100|    2|\n|      Michael|     Sales|  4600|    2|\n+-------------+----------+------+-----+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import ntile\n",
    "df.withColumn(\"ntile\",ntile(2).over(windowSpec)) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "df15a830-5154-46f0-a024-033989d8a955",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------------+----------+------+------------------+\n",
       "employee_name|department|salary|         cume_dist|\n",
       "+-------------+----------+------+------------------+\n",
       "        Maria|   Finance|  3000|0.3333333333333333|\n",
       "        Scott|   Finance|  3300|0.6666666666666666|\n",
       "          Jen|   Finance|  3900|               1.0|\n",
       "        Kumar| Marketing|  2000|               0.5|\n",
       "         Jeff| Marketing|  3000|               1.0|\n",
       "        James|     Sales|  3000|               0.4|\n",
       "        James|     Sales|  3000|               0.4|\n",
       "       Robert|     Sales|  4100|               0.8|\n",
       "         Saif|     Sales|  4100|               0.8|\n",
       "      Michael|     Sales|  4600|               1.0|\n",
       "+-------------+----------+------+------------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-------------+----------+------+------------------+\n|employee_name|department|salary|         cume_dist|\n+-------------+----------+------+------------------+\n|        Maria|   Finance|  3000|0.3333333333333333|\n|        Scott|   Finance|  3300|0.6666666666666666|\n|          Jen|   Finance|  3900|               1.0|\n|        Kumar| Marketing|  2000|               0.5|\n|         Jeff| Marketing|  3000|               1.0|\n|        James|     Sales|  3000|               0.4|\n|        James|     Sales|  3000|               0.4|\n|       Robert|     Sales|  4100|               0.8|\n|         Saif|     Sales|  4100|               0.8|\n|      Michael|     Sales|  4600|               1.0|\n+-------------+----------+------+------------------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import cume_dist    \n",
    "df.withColumn(\"cume_dist\",cume_dist().over(windowSpec)) \\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "169f5602-c292-4529-b070-4b162ee9548d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------------+----------+------+----+\n",
       "employee_name|department|salary| lag|\n",
       "+-------------+----------+------+----+\n",
       "        Maria|   Finance|  3000|null|\n",
       "        Scott|   Finance|  3300|null|\n",
       "          Jen|   Finance|  3900|3000|\n",
       "        Kumar| Marketing|  2000|null|\n",
       "         Jeff| Marketing|  3000|null|\n",
       "        James|     Sales|  3000|null|\n",
       "        James|     Sales|  3000|null|\n",
       "       Robert|     Sales|  4100|3000|\n",
       "         Saif|     Sales|  4100|3000|\n",
       "      Michael|     Sales|  4600|4100|\n",
       "+-------------+----------+------+----+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-------------+----------+------+----+\n|employee_name|department|salary| lag|\n+-------------+----------+------+----+\n|        Maria|   Finance|  3000|null|\n|        Scott|   Finance|  3300|null|\n|          Jen|   Finance|  3900|3000|\n|        Kumar| Marketing|  2000|null|\n|         Jeff| Marketing|  3000|null|\n|        James|     Sales|  3000|null|\n|        James|     Sales|  3000|null|\n|       Robert|     Sales|  4100|3000|\n|         Saif|     Sales|  4100|3000|\n|      Michael|     Sales|  4600|4100|\n+-------------+----------+------+----+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import lag    \n",
    "df.withColumn(\"lag\",lag(\"salary\",2).over(windowSpec)) \\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "898aa6a6-8091-4a69-ba50-d9be920adfa6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------------+----------+------+----+\n",
       "employee_name|department|salary|lead|\n",
       "+-------------+----------+------+----+\n",
       "        Maria|   Finance|  3000|3900|\n",
       "        Scott|   Finance|  3300|null|\n",
       "          Jen|   Finance|  3900|null|\n",
       "        Kumar| Marketing|  2000|null|\n",
       "         Jeff| Marketing|  3000|null|\n",
       "        James|     Sales|  3000|4100|\n",
       "        James|     Sales|  3000|4100|\n",
       "       Robert|     Sales|  4100|4600|\n",
       "         Saif|     Sales|  4100|null|\n",
       "      Michael|     Sales|  4600|null|\n",
       "+-------------+----------+------+----+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-------------+----------+------+----+\n|employee_name|department|salary|lead|\n+-------------+----------+------+----+\n|        Maria|   Finance|  3000|3900|\n|        Scott|   Finance|  3300|null|\n|          Jen|   Finance|  3900|null|\n|        Kumar| Marketing|  2000|null|\n|         Jeff| Marketing|  3000|null|\n|        James|     Sales|  3000|4100|\n|        James|     Sales|  3000|4100|\n|       Robert|     Sales|  4100|4600|\n|         Saif|     Sales|  4100|null|\n|      Michael|     Sales|  4600|null|\n+-------------+----------+------+----+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import lead    \n",
    "df.withColumn(\"lead\",lead(\"salary\",2).over(windowSpec)) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c81092f0-513b-4048-8889-58da85b786c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----------+------+-----+----+----+\n",
       "department|   avg|  sum| min| max|\n",
       "+----------+------+-----+----+----+\n",
       "   Finance|3400.0|10200|3000|3900|\n",
       " Marketing|2500.0| 5000|2000|3000|\n",
       "     Sales|3760.0|18800|3000|4600|\n",
       "+----------+------+-----+----+----+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+----------+------+-----+----+----+\n|department|   avg|  sum| min| max|\n+----------+------+-----+----+----+\n|   Finance|3400.0|10200|3000|3900|\n| Marketing|2500.0| 5000|2000|3000|\n|     Sales|3760.0|18800|3000|4600|\n+----------+------+-----+----+----+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "windowSpecAgg  = Window.partitionBy(\"department\")\n",
    "from pyspark.sql.functions import col,avg,sum,min,max,row_number \n",
    "\n",
    "df.withColumn(\"row\",row_number().over(windowSpec)) \\\n",
    "  .withColumn(\"avg\", avg(col(\"salary\")).over(windowSpecAgg)) \\\n",
    "  .withColumn(\"sum\", sum(col(\"salary\")).over(windowSpecAgg)) \\\n",
    "  .withColumn(\"min\", min(col(\"salary\")).over(windowSpecAgg)) \\\n",
    "  .withColumn(\"max\", max(col(\"salary\")).over(windowSpecAgg)) \\\n",
    "  .where(col(\"row\")==1).select(\"department\",\"avg\",\"sum\",\"min\",\"max\") \\\n",
    "  .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b7e95a08-81d0-480a-a7aa-b3651af2567f",
     "showTitle": true,
     "title": "When Otherwise"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">root\n",
       "-- first_name: string (nullable = true)\n",
       "-- middle_name: string (nullable = true)\n",
       "-- last_name: string (nullable = true)\n",
       "-- dob: string (nullable = true)\n",
       "-- gender: string (nullable = true)\n",
       "-- salary: long (nullable = true)\n",
       "\n",
       "+----------+-----------+---------+-----+------+------+\n",
       "first_name|middle_name|last_name|dob  |gender|salary|\n",
       "+----------+-----------+---------+-----+------+------+\n",
       "James     |           |Smith    |36636|M     |60000 |\n",
       "Michael   |Rose       |         |40288|M     |70000 |\n",
       "Robert    |           |Williams |42114|      |400000|\n",
       "Maria     |Anne       |Jones    |39192|F     |500000|\n",
       "Jen       |Mary       |Brown    |     |F     |0     |\n",
       "+----------+-----------+---------+-----+------+------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">root\n |-- first_name: string (nullable = true)\n |-- middle_name: string (nullable = true)\n |-- last_name: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+----------+-----------+---------+-----+------+------+\n|first_name|middle_name|last_name|dob  |gender|salary|\n+----------+-----------+---------+-----+------+------+\n|James     |           |Smith    |36636|M     |60000 |\n|Michael   |Rose       |         |40288|M     |70000 |\n|Robert    |           |Williams |42114|      |400000|\n|Maria     |Anne       |Jones    |39192|F     |500000|\n|Jen       |Mary       |Brown    |     |F     |0     |\n+----------+-----------+---------+-----+------+------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",60000),\n",
    "        (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",70000),\n",
    "        (\"Robert\",\"\",\"Williams\",\"42114\",\"\",400000),\n",
    "        (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",500000),\n",
    "        (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",0)]\n",
    "\n",
    "columns = [\"first_name\",\"middle_name\",\"last_name\",\"dob\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c1e828c4-3051-4cc9-b67f-58459c0d7298",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-1489946428265218&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># Using when otherwise</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>functions <span class=\"ansi-green-fg\">import</span> col<span class=\"ansi-blue-fg\">,</span> when\n",
       "<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> df2 = df.withColumn(&#34;new_gender&#34;, when(col(&#34;gender&#34;) == &#34;M&#34;,&#34;Male&#34;)\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">      4</span>                                  <span class=\"ansi-blue-fg\">.</span>when<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;gender&#34;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-blue-fg\">&#34;F&#34;</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#34;Female&#34;</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>                                  .otherwise(&#34;Unknown&#34;))\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">withColumn</span><span class=\"ansi-blue-fg\">(self, colName, col)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   2476</span>         &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   2477</span>         <span class=\"ansi-green-fg\">assert</span> isinstance<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">,</span> Column<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;col should be Column&#34;</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 2478</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span>colName<span class=\"ansi-blue-fg\">,</span> col<span class=\"ansi-blue-fg\">.</span>_jc<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   2479</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   2480</span>     <span class=\"ansi-green-fg\">def</span> withColumnRenamed<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> existing<span class=\"ansi-blue-fg\">,</span> new<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    114</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 116</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    117</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>                 <span class=\"ansi-green-fg\">raise</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`gender`&#39; given input columns: [Amount, Country, Product];\n",
       "&#39;Project [Product#603, Amount#604L, Country#605, CASE WHEN (&#39;gender = M) THEN Male WHEN (&#39;gender = F) THEN Female ELSE Unknown END AS new_gender#828]\n",
       "+- LogicalRDD [Product#603, Amount#604L, Country#605], false\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1489946428265218&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># Using when otherwise</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> <span class=\"ansi-green-fg\">from</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>functions <span class=\"ansi-green-fg\">import</span> col<span class=\"ansi-blue-fg\">,</span> when\n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> df2 = df.withColumn(&#34;new_gender&#34;, when(col(&#34;gender&#34;) == &#34;M&#34;,&#34;Male&#34;)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      4</span>                                  <span class=\"ansi-blue-fg\">.</span>when<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;gender&#34;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-blue-fg\">&#34;F&#34;</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#34;Female&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>                                  .otherwise(&#34;Unknown&#34;))\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">withColumn</span><span class=\"ansi-blue-fg\">(self, colName, col)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2476</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">   2477</span>         <span class=\"ansi-green-fg\">assert</span> isinstance<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">,</span> Column<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;col should be Column&#34;</span>\n<span class=\"ansi-green-fg\">-&gt; 2478</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span>colName<span class=\"ansi-blue-fg\">,</span> col<span class=\"ansi-blue-fg\">.</span>_jc<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2479</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   2480</span>     <span class=\"ansi-green-fg\">def</span> withColumnRenamed<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> existing<span class=\"ansi-blue-fg\">,</span> new<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    114</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 116</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    117</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`gender`&#39; given input columns: [Amount, Country, Product];\n&#39;Project [Product#603, Amount#604L, Country#605, CASE WHEN (&#39;gender = M) THEN Male WHEN (&#39;gender = F) THEN Female ELSE Unknown END AS new_gender#828]\n+- LogicalRDD [Product#603, Amount#604L, Country#605], false\n</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`gender`&#39; given input columns: [Amount, Country, Product];",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using when otherwise\n",
    "from pyspark.sql.functions import col, when\n",
    "df2 = df.withColumn(\"new_gender\", when(col(\"gender\") == \"M\",\"Male\")\n",
    "                                 .when(col(\"gender\") == \"F\",\"Female\")\n",
    "                                 .otherwise(\"Unknown\"))\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0a0ec380-6154-47fe-b55b-fca8429d1073",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-1489946428265219&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> df22=df.select(col(&#34;*&#34;), when(col(&#34;gender&#34;) == &#34;M&#34;,&#34;Male&#34;)\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">      2</span>       <span class=\"ansi-blue-fg\">.</span>when<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;gender&#34;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-blue-fg\">&#34;F&#34;</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#34;Female&#34;</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>       .otherwise(&#34;Unknown&#34;).alias(&#34;new_gender&#34;)).show(truncate=False)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> <span class=\"ansi-red-fg\"># Using case when</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">select</span><span class=\"ansi-blue-fg\">(self, *cols)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1690</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Alice&#39;</span><span class=\"ansi-blue-fg\">,</span> age<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">12</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Bob&#39;</span><span class=\"ansi-blue-fg\">,</span> age<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">15</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1691</span>         &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-fg\">-&gt; 1692</span><span class=\"ansi-red-fg\">         </span>jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jcols<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>cols<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1693</span>         <span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>jdf<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1694</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    114</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 116</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    117</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>                 <span class=\"ansi-green-fg\">raise</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`gender`&#39; given input columns: [Amount, Country, Product];\n",
       "&#39;Project [Product#603, Amount#604L, Country#605, CASE WHEN (&#39;gender = M) THEN Male WHEN (&#39;gender = F) THEN Female ELSE Unknown END AS new_gender#829]\n",
       "+- LogicalRDD [Product#603, Amount#604L, Country#605], false\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1489946428265219&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> df22=df.select(col(&#34;*&#34;), when(col(&#34;gender&#34;) == &#34;M&#34;,&#34;Male&#34;)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      2</span>       <span class=\"ansi-blue-fg\">.</span>when<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;gender&#34;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-blue-fg\">&#34;F&#34;</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#34;Female&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>       .otherwise(&#34;Unknown&#34;).alias(&#34;new_gender&#34;)).show(truncate=False)\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> <span class=\"ansi-red-fg\"># Using case when</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">select</span><span class=\"ansi-blue-fg\">(self, *cols)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1690</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Alice&#39;</span><span class=\"ansi-blue-fg\">,</span> age<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">12</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Bob&#39;</span><span class=\"ansi-blue-fg\">,</span> age<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">15</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1691</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">-&gt; 1692</span><span class=\"ansi-red-fg\">         </span>jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jcols<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>cols<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1693</span>         <span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>jdf<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1694</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    114</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 116</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    117</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`gender`&#39; given input columns: [Amount, Country, Product];\n&#39;Project [Product#603, Amount#604L, Country#605, CASE WHEN (&#39;gender = M) THEN Male WHEN (&#39;gender = F) THEN Female ELSE Unknown END AS new_gender#829]\n+- LogicalRDD [Product#603, Amount#604L, Country#605], false\n</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`gender`&#39; given input columns: [Amount, Country, Product];",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df22=df.select(col(\"*\"), when(col(\"gender\") == \"M\",\"Male\")\n",
    "      .when(col(\"gender\") == \"F\",\"Female\")\n",
    "      .otherwise(\"Unknown\").alias(\"new_gender\")).show(truncate=False)\n",
    "\n",
    "# Using case when\n",
    "from pyspark.sql.functions import expr\n",
    "df3 = df.withColumn(\"new_gender\", expr(\"case when gender = 'M' then 'Male' \" + \n",
    "                       \"when gender = 'F' then 'Female' \" +\n",
    "                       \"else 'Unknown' end\"))\n",
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "27e493ae-2293-4a1b-9276-d0ce662b8fe1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-1489946428265220&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\">#Using case when</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> df4 = df.select(col(&#34;*&#34;), expr(&#34;case when gender = &#39;M&#39; then &#39;Male&#39; &#34; +\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">      3</span>                        <span class=\"ansi-blue-fg\">&#34;when gender = &#39;F&#39; then &#39;Female&#39; &#34;</span> <span class=\"ansi-blue-fg\">+</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>                        &#34;else &#39;Unknown&#39; end&#34;).alias(&#34;new_gender&#34;))\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> df4<span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span>truncate<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">select</span><span class=\"ansi-blue-fg\">(self, *cols)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1690</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Alice&#39;</span><span class=\"ansi-blue-fg\">,</span> age<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">12</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Bob&#39;</span><span class=\"ansi-blue-fg\">,</span> age<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">15</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1691</span>         &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-fg\">-&gt; 1692</span><span class=\"ansi-red-fg\">         </span>jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jcols<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>cols<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1693</span>         <span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>jdf<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1694</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    114</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 116</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    117</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>                 <span class=\"ansi-green-fg\">raise</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`gender`&#39; given input columns: [Amount, Country, Product]; line 1 pos 10;\n",
       "&#39;Project [Product#603, Amount#604L, Country#605, CASE WHEN (&#39;gender = M) THEN Male WHEN (&#39;gender = F) THEN Female ELSE Unknown END AS new_gender#821]\n",
       "+- LogicalRDD [Product#603, Amount#604L, Country#605], false\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1489946428265220&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\">#Using case when</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> df4 = df.select(col(&#34;*&#34;), expr(&#34;case when gender = &#39;M&#39; then &#39;Male&#39; &#34; +\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      3</span>                        <span class=\"ansi-blue-fg\">&#34;when gender = &#39;F&#39; then &#39;Female&#39; &#34;</span> <span class=\"ansi-blue-fg\">+</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>                        &#34;else &#39;Unknown&#39; end&#34;).alias(&#34;new_gender&#34;))\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> df4<span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span>truncate<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">select</span><span class=\"ansi-blue-fg\">(self, *cols)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1690</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Alice&#39;</span><span class=\"ansi-blue-fg\">,</span> age<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">12</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;Bob&#39;</span><span class=\"ansi-blue-fg\">,</span> age<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">15</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1691</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">-&gt; 1692</span><span class=\"ansi-red-fg\">         </span>jdf <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jcols<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>cols<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1693</span>         <span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>jdf<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1694</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    114</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 116</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    117</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`gender`&#39; given input columns: [Amount, Country, Product]; line 1 pos 10;\n&#39;Project [Product#603, Amount#604L, Country#605, CASE WHEN (&#39;gender = M) THEN Male WHEN (&#39;gender = F) THEN Female ELSE Unknown END AS new_gender#821]\n+- LogicalRDD [Product#603, Amount#604L, Country#605], false\n</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">AnalysisException</span>: cannot resolve &#39;`gender`&#39; given input columns: [Amount, Country, Product]; line 1 pos 10;",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Using case when\n",
    "df4 = df.select(col(\"*\"), expr(\"case when gender = 'M' then 'Male' \" +\n",
    "                       \"when gender = 'F' then 'Female' \" +\n",
    "                       \"else 'Unknown' end\").alias(\"new_gender\"))\n",
    "df4.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8b3c7fce-beae-4f96-81ad-47713f71c677",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">Py4JError</span>                                 Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-1489946428265221&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> \n",
       "<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\"> df5.withColumn(&#34;new_column&#34;, when(col(&#34;code&#34;) == &#34;a&#34; | col(&#34;code&#34;) == &#34;d&#34;, &#34;A&#34;)\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">      6</span>       <span class=\"ansi-blue-fg\">.</span>when<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;code&#34;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-blue-fg\">&#34;b&#34;</span> <span class=\"ansi-blue-fg\">&amp;</span> col<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;amt&#34;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-blue-fg\">&#34;4&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;B&#34;</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      7</span>       .otherwise(&#34;A1&#34;)).show()\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/column.py</span> in <span class=\"ansi-cyan-fg\">_</span><span class=\"ansi-blue-fg\">(self, other)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    110</span>     <span class=\"ansi-green-fg\">def</span> _<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> other<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    111</span>         jc <span class=\"ansi-blue-fg\">=</span> other<span class=\"ansi-blue-fg\">.</span>_jc <span class=\"ansi-green-fg\">if</span> isinstance<span class=\"ansi-blue-fg\">(</span>other<span class=\"ansi-blue-fg\">,</span> Column<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">else</span> other\n",
       "<span class=\"ansi-green-fg\">--&gt; 112</span><span class=\"ansi-red-fg\">         </span>njc <span class=\"ansi-blue-fg\">=</span> getattr<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jc<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">(</span>jc<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    113</span>         <span class=\"ansi-green-fg\">return</span> Column<span class=\"ansi-blue-fg\">(</span>njc<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    114</span>     _<span class=\"ansi-blue-fg\">.</span>__doc__ <span class=\"ansi-blue-fg\">=</span> doc\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    108</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    109</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 110</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    111</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    112</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    328</span>                     format(target_id, &#34;.&#34;, name), value)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 330</span><span class=\"ansi-red-fg\">                 raise Py4JError(\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">    331</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    332</span>                     format(target_id, &#34;.&#34;, name, value))\n",
       "\n",
       "<span class=\"ansi-red-fg\">Py4JError</span>: An error occurred while calling o1061.or. Trace:\n",
       "py4j.Py4JException: Method or([class java.lang.String]) does not exist\n",
       "\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:341)\n",
       "\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:349)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:286)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n",
       "\tat java.lang.Thread.run(Thread.java:748)\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1489946428265221&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> \n<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\"> df5.withColumn(&#34;new_column&#34;, when(col(&#34;code&#34;) == &#34;a&#34; | col(&#34;code&#34;) == &#34;d&#34;, &#34;A&#34;)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      6</span>       <span class=\"ansi-blue-fg\">.</span>when<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;code&#34;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-blue-fg\">&#34;b&#34;</span> <span class=\"ansi-blue-fg\">&amp;</span> col<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;amt&#34;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">==</span> <span class=\"ansi-blue-fg\">&#34;4&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;B&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span>       .otherwise(&#34;A1&#34;)).show()\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/column.py</span> in <span class=\"ansi-cyan-fg\">_</span><span class=\"ansi-blue-fg\">(self, other)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    110</span>     <span class=\"ansi-green-fg\">def</span> _<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> other<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    111</span>         jc <span class=\"ansi-blue-fg\">=</span> other<span class=\"ansi-blue-fg\">.</span>_jc <span class=\"ansi-green-fg\">if</span> isinstance<span class=\"ansi-blue-fg\">(</span>other<span class=\"ansi-blue-fg\">,</span> Column<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">else</span> other\n<span class=\"ansi-green-fg\">--&gt; 112</span><span class=\"ansi-red-fg\">         </span>njc <span class=\"ansi-blue-fg\">=</span> getattr<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jc<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">(</span>jc<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    113</span>         <span class=\"ansi-green-fg\">return</span> Column<span class=\"ansi-blue-fg\">(</span>njc<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    114</span>     _<span class=\"ansi-blue-fg\">.</span>__doc__ <span class=\"ansi-blue-fg\">=</span> doc\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    108</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    109</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 110</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    111</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    112</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    328</span>                     format(target_id, &#34;.&#34;, name), value)\n<span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 330</span><span class=\"ansi-red-fg\">                 raise Py4JError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    331</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    332</span>                     format(target_id, &#34;.&#34;, name, value))\n\n<span class=\"ansi-red-fg\">Py4JError</span>: An error occurred while calling o1061.or. Trace:\npy4j.Py4JException: Method or([class java.lang.String]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:341)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:349)\n\tat py4j.Gateway.invoke(Gateway.java:286)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n\n</div>",
       "errorSummary": "py4j.Py4JException: Method or([class java.lang.String]) does not exist",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data2 = [(66, \"a\", \"4\"), (67, \"a\", \"0\"), (70, \"b\", \"4\"), (71, \"d\", \"4\")]\n",
    "df5 = spark.createDataFrame(data = data2, schema = [\"id\", \"code\", \"amt\"])\n",
    "         \n",
    "\n",
    "df5.withColumn(\"new_column\", when(col(\"code\") == \"a\" | col(\"code\") == \"d\", \"A\")\n",
    "      .when(col(\"code\") == \"b\" & col(\"amt\") == \"4\", \"B\")\n",
    "      .otherwise(\"A1\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9e55eaf9-3c2a-4264-b83b-a2df02aa8de1",
     "showTitle": true,
     "title": "Pivot"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">root\n",
       "-- Product: string (nullable = true)\n",
       "-- Amount: long (nullable = true)\n",
       "-- Country: string (nullable = true)\n",
       "\n",
       "+-------+------+-------+\n",
       "Product|Amount|Country|\n",
       "+-------+------+-------+\n",
       "Banana |1000  |USA    |\n",
       "Carrots|1500  |USA    |\n",
       "Beans  |1600  |USA    |\n",
       "Orange |2000  |USA    |\n",
       "Orange |2000  |USA    |\n",
       "Banana |400   |China  |\n",
       "Carrots|1200  |China  |\n",
       "Beans  |1500  |China  |\n",
       "Orange |4000  |China  |\n",
       "Banana |2000  |Canada |\n",
       "Carrots|2000  |Canada |\n",
       "Beans  |2000  |Mexico |\n",
       "+-------+------+-------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">root\n |-- Product: string (nullable = true)\n |-- Amount: long (nullable = true)\n |-- Country: string (nullable = true)\n\n+-------+------+-------+\n|Product|Amount|Country|\n+-------+------+-------+\n|Banana |1000  |USA    |\n|Carrots|1500  |USA    |\n|Beans  |1600  |USA    |\n|Orange |2000  |USA    |\n|Orange |2000  |USA    |\n|Banana |400   |China  |\n|Carrots|1200  |China  |\n|Beans  |1500  |China  |\n|Orange |4000  |China  |\n|Banana |2000  |Canada |\n|Carrots|2000  |Canada |\n|Beans  |2000  |Mexico |\n+-------+------+-------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "data = [(\"Banana\",1000,\"USA\"), (\"Carrots\",1500,\"USA\"), (\"Beans\",1600,\"USA\"), \\\n",
    "      (\"Orange\",2000,\"USA\"),(\"Orange\",2000,\"USA\"),(\"Banana\",400,\"China\"), \\\n",
    "      (\"Carrots\",1200,\"China\"),(\"Beans\",1500,\"China\"),(\"Orange\",4000,\"China\"), \\\n",
    "      (\"Banana\",2000,\"Canada\"),(\"Carrots\",2000,\"Canada\"),(\"Beans\",2000,\"Mexico\")]\n",
    "\n",
    "columns= [\"Product\",\"Amount\",\"Country\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9b38cc4d-39cd-417a-b5d6-48f2d27fd24f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">root\n",
       "-- Product: string (nullable = true)\n",
       "-- Canada: long (nullable = true)\n",
       "-- China: long (nullable = true)\n",
       "-- Mexico: long (nullable = true)\n",
       "-- USA: long (nullable = true)\n",
       "\n",
       "+-------+------+-----+------+----+\n",
       "Product|Canada|China|Mexico|USA |\n",
       "+-------+------+-----+------+----+\n",
       "Orange |null  |4000 |null  |4000|\n",
       "Beans  |null  |1500 |2000  |1600|\n",
       "Banana |2000  |400  |null  |1000|\n",
       "Carrots|2000  |1200 |null  |1500|\n",
       "+-------+------+-----+------+----+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">root\n |-- Product: string (nullable = true)\n |-- Canada: long (nullable = true)\n |-- China: long (nullable = true)\n |-- Mexico: long (nullable = true)\n |-- USA: long (nullable = true)\n\n+-------+------+-----+------+----+\n|Product|Canada|China|Mexico|USA |\n+-------+------+-----+------+----+\n|Orange |null  |4000 |null  |4000|\n|Beans  |null  |1500 |2000  |1600|\n|Banana |2000  |400  |null  |1000|\n|Carrots|2000  |1200 |null  |1500|\n+-------+------+-----+------+----+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pivotDF = df.groupBy(\"Product\").pivot(\"Country\").sum(\"Amount\")\n",
    "pivotDF.printSchema()\n",
    "pivotDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cd96f05f-3530-40b1-b14e-e9a38b3424d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">root\n",
       "-- Product: string (nullable = true)\n",
       "-- Canada: long (nullable = true)\n",
       "-- China: long (nullable = true)\n",
       "-- Mexico: long (nullable = true)\n",
       "-- USA: long (nullable = true)\n",
       "\n",
       "+-------+------+-----+------+----+\n",
       "Product|Canada|China|Mexico|USA |\n",
       "+-------+------+-----+------+----+\n",
       "Orange |null  |4000 |null  |4000|\n",
       "Beans  |null  |1500 |2000  |1600|\n",
       "Banana |2000  |400  |null  |1000|\n",
       "Carrots|2000  |1200 |null  |1500|\n",
       "+-------+------+-----+------+----+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">root\n |-- Product: string (nullable = true)\n |-- Canada: long (nullable = true)\n |-- China: long (nullable = true)\n |-- Mexico: long (nullable = true)\n |-- USA: long (nullable = true)\n\n+-------+------+-----+------+----+\n|Product|Canada|China|Mexico|USA |\n+-------+------+-----+------+----+\n|Orange |null  |4000 |null  |4000|\n|Beans  |null  |1500 |2000  |1600|\n|Banana |2000  |400  |null  |1000|\n|Carrots|2000  |1200 |null  |1500|\n+-------+------+-----+------+----+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pivotDF = df.groupBy(\"Product\",\"Country\") \\\n",
    "      .sum(\"Amount\") \\\n",
    "      .groupBy(\"Product\") \\\n",
    "      .pivot(\"Country\") \\\n",
    "      .sum(\"sum(Amount)\")\n",
    "pivotDF.printSchema()\n",
    "pivotDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ca269efb-fc4c-418e-be38-ac86d0624625",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------+-------+-----+\n",
       "Product|Country|Total|\n",
       "+-------+-------+-----+\n",
       "Orange |China  |4000 |\n",
       "Beans  |China  |1500 |\n",
       "Beans  |Mexico |2000 |\n",
       "Banana |Canada |2000 |\n",
       "Banana |China  |400  |\n",
       "Carrots|Canada |2000 |\n",
       "Carrots|China  |1200 |\n",
       "+-------+-------+-----+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-------+-------+-----+\n|Product|Country|Total|\n+-------+-------+-----+\n|Orange |China  |4000 |\n|Beans  |China  |1500 |\n|Beans  |Mexico |2000 |\n|Banana |Canada |2000 |\n|Banana |China  |400  |\n|Carrots|Canada |2000 |\n|Carrots|China  |1200 |\n+-------+-------+-----+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" unpivot \"\"\"\n",
    "unpivotExpr = \"stack(3, 'Canada', Canada, 'China', China, 'Mexico', Mexico) as (Country,Total)\"\n",
    "unPivotDF = pivotDF.select(\"Product\", expr(unpivotExpr)) \\\n",
    "    .where(\"Total is not null\")\n",
    "unPivotDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "859edd6d-08b4-475e-bc49-95c66aaa1d5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----------+----------+-------+\n",
       "   product|  category|revenue|\n",
       "+----------+----------+-------+\n",
       "      Thin|Cell phone|   6000|\n",
       "    Normal|    Tablet|   1500|\n",
       "      Mini|    Tablet|   5500|\n",
       "Ultra thin|Cell phone|   5000|\n",
       "  Vey thin|Cell phone|   6000|\n",
       "       Big|    Tablet|   2500|\n",
       "  Bendable|Cell phone|   3000|\n",
       "  Foldable|Cell phone|   3000|\n",
       "       Pro|    Tablet|   5400|\n",
       "      Pro2|    Tablet|   6500|\n",
       "+----------+----------+-------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+----------+----------+-------+\n|   product|  category|revenue|\n+----------+----------+-------+\n|      Thin|Cell phone|   6000|\n|    Normal|    Tablet|   1500|\n|      Mini|    Tablet|   5500|\n|Ultra thin|Cell phone|   5000|\n|  Vey thin|Cell phone|   6000|\n|       Big|    Tablet|   2500|\n|  Bendable|Cell phone|   3000|\n|  Foldable|Cell phone|   3000|\n|       Pro|    Tablet|   5400|\n|      Pro2|    Tablet|   6500|\n+----------+----------+-------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").getOrCreate()\n",
    "\n",
    "data = [\n",
    "    ('Thin', 'Cell phone', 6000),\n",
    "    ('Normal', 'Tablet', 1500),\n",
    "    ('Mini', 'Tablet', 5500),\n",
    "    ('Ultra thin', 'Cell phone', 5000),\n",
    "    ('Vey thin', 'Cell phone', 6000),\n",
    "    ('Big', 'Tablet', 2500),\n",
    "    ('Bendable', 'Cell phone', 3000),\n",
    "    ('Foldable', 'Cell phone', 3000),\n",
    "    ('Pro', 'Tablet', 5400),\n",
    "    ('Pro2', 'Tablet', 6500)\n",
    "]\n",
    "\n",
    "products = spark.createDataFrame(data, ['product', 'category', 'revenue'])\n",
    "\n",
    "products.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e2116394-35cc-438c-bfe0-7168fc05783e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Ответьте на следующие вопросы:\n",
    "\n",
    "1) Какой продукт является самым продаваемым в каждой категории?\n",
    "2) Каковы наибольшие и вторые наибольшие по продажам продукты в каждой категории?\n",
    "3) Найдите разницу между доходом от каждого продукта и самым продаваемым продуктом в той же категории продукта?\n",
    "4) Найдите разницу между доходом каждого продукта и средним доходом категории, если этот продукт?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f8027535-a6ce-4dc9-a686-d6c70d0a4761",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----------+----+\n",
       "category  |best|\n",
       "+----------+----+\n",
       "Cell phone|6000|\n",
       "Tablet    |6500|\n",
       "+----------+----+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+----------+----+\n|category  |best|\n+----------+----+\n|Cell phone|6000|\n|Tablet    |6500|\n+----------+----+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "products.groupBy(\"category\") \\\n",
    "    .agg(F.max(\"revenue\").alias(\"best\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2c25790f-3b8f-4933-9245-2f6eaca38ee0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+----------+-------+----+\n",
       "product |category  |revenue|rank|\n",
       "+--------+----------+-------+----+\n",
       "Bendable|Cell phone|3000   |1   |\n",
       "Foldable|Cell phone|3000   |1   |\n",
       "Normal  |Tablet    |1500   |1   |\n",
       "+--------+----------+-------+----+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+----------+-------+----+\n|product |category  |revenue|rank|\n+--------+----------+-------+----+\n|Bendable|Cell phone|3000   |1   |\n|Foldable|Cell phone|3000   |1   |\n|Normal  |Tablet    |1500   |1   |\n+--------+----------+-------+----+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "windowSpec  = Window.partitionBy(\"category\").orderBy(\"revenue\")\n",
    "\n",
    "products.withColumn(\"rank\", F.rank().over(windowSpec)).where(F.col(\"rank\") == 1)  \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9a7e02b0-72c6-48bf-9ebe-4fdb2038a907",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+----------+-------+\n",
       "product |category  |revenue|\n",
       "+--------+----------+-------+\n",
       "Bendable|Cell phone|3000   |\n",
       "Foldable|Cell phone|3000   |\n",
       "Normal  |Tablet    |1500   |\n",
       "Big     |Tablet    |2500   |\n",
       "+--------+----------+-------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+--------+----------+-------+\n|product |category  |revenue|\n+--------+----------+-------+\n|Bendable|Cell phone|3000   |\n|Foldable|Cell phone|3000   |\n|Normal  |Tablet    |1500   |\n|Big     |Tablet    |2500   |\n+--------+----------+-------+\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "products.withColumn(\"row_number\", F.row_number().over(windowSpec)).where(F.col(\"row_number\") <= 2).drop(\"row_number\")  \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "58d46dae-a3ce-469e-86f4-8f836c9d89b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "drop(columns=)\n",
    "select(\"nam1\", \"name2\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Seminar3 (1)",
   "notebookOrigID": 1551382878540245,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
