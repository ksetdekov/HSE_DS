# Потоковые данные
# проблемы
1. их как-то надо приводить к общему формату
2. они постоянно идут, мы хотим какую-то метрику онлайн получать.

# сценарии отказа
## отказ во время обработки
оператор 2 не посчитал и это наблюдение никуда не пошло.

при цепной обработке - нужно чтобы обратно от агента 2 в агент 1 шла информация при успешной обработке сообщал

## отказ во время отправки ответа о результатах обработки

мы не остановили ретрай и сгенерировали слишком много данных на шаге 3.

# проблема византийских генералов
## задача

нужно в 4 согласовать время нападения

Если они не согласуются все - то проиграют

Между ними есть обмен сообщений, но каналы могут быть враждебны - перехватывать и или менять сообщения.

такая же постановка проблемы, аналогично тому что в спарк стриминге есть и решено

# Лямбда архитектура        

решения - подождать, собрать данные в батч и его обработать целиком

2 вариант - обработка налету + обработка кусками.

## подбробнее

* есть speed layer - в нем stream processing  он выдает incremental views
* есть batch layer - в нем все данные обрабатываеются в pre-compute views
* есть serving layer - в нем batch view + realtime view отдаются под запросы и принимются на вход стримы данных

не нужно будет в спарке дублировать и по разному писать код speed layer и batch layer

## spark straming

расширение API Spark. Данные из разных источников могу быть получены из разных способов. Спарк подключается к Kafka как источник.

## dstream - это дискретизированный поток
абстракция внутри spark streaming

бьем данные на интервалы и создаем внутри RDD

lines datastream convert to word datastream

# ML & DStream

wowpal wabit - в моменте легко переобучается

